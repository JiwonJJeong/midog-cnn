{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b965ba59-c83e-4dac-b15e-faa68f5da526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import warnings # For handling potential PIL warnings\n",
    "import math # NEW IMPORT for floor/ceil rounding\n",
    "\n",
    "# --- CONFIGURATION CONSTANTS ---\n",
    "# The new size is 50 (original) + 5 (left) + 5 (right) = 60\n",
    "TARGET_PATCH_DIMENSION = 60 \n",
    "PADDING = 5\n",
    "# --------------------------------\n",
    "\n",
    "def preprocess_and_save_patches_optimized(\n",
    "    df_merged: pd.DataFrame, \n",
    "    source_image_dir: str = 'images/', \n",
    "    target_patch_dir: str = 'cropped_images/' # Recommended new name\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimized function: Loads each source image ONCE and extracts all associated patches.\n",
    "    Applies numeric stability, 5-pixel padding, and size guarantee (60x60).\n",
    "    \"\"\"\n",
    "    print(f\"Starting optimized pre-processing and saving of {TARGET_PATCH_DIMENSION}x{TARGET_PATCH_DIMENSION} image patches...\")\n",
    "    \n",
    "    os.makedirs(target_patch_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Prepare helper columns\n",
    "    df_merged['file_id'] = df_merged['image_id'].astype(int).apply(lambda x: f\"{x:03d}\")\n",
    "    df_merged['patch_id'] = df_merged.index\n",
    "\n",
    "    # 2. GROUP THE DATAFRAME by the source image ID (file_id)\n",
    "    grouped_df = df_merged.groupby('file_id')\n",
    "    \n",
    "    total_images = len(grouped_df)\n",
    "    total_patches = len(df_merged)\n",
    "\n",
    "    # 3. Outer Loop: Iterate through each unique source image\n",
    "    tqdm_images = tqdm(\n",
    "        grouped_df, \n",
    "        total=total_images, \n",
    "        desc=f\"Processing {total_patches} patches from {total_images} images\"\n",
    "    )\n",
    "\n",
    "    current_image = None\n",
    "\n",
    "    for file_id, image_group in tqdm_images:\n",
    "        \n",
    "        # --- A. Load the Image ONCE ---\n",
    "        original_img_name = os.path.join(source_image_dir, f\"{file_id}.tiff\")\n",
    "        \n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", Image.DecompressionBombWarning)\n",
    "                current_image = Image.open(original_img_name).convert('RGB')\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            tqdm_images.write(f\"\\nWarning: Original image not found for ID {file_id} at path: {original_img_name}\")\n",
    "            current_image = None\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            tqdm_images.write(f\"\\nError loading image {file_id}: {e}\")\n",
    "            current_image = None\n",
    "            continue\n",
    "\n",
    "        # --- B. Inner Loop: Process all patches for this loaded image ---\n",
    "        for index, row in image_group.iterrows():\n",
    "            if current_image is None:\n",
    "                continue\n",
    "                \n",
    "            patch_filename = os.path.join(target_patch_dir, f\"{row['patch_id']}.png\")\n",
    "            \n",
    "            # Skip if the patch already exists (for resuming)\n",
    "            # NOTE: If you are rerunning to fix the 49x50 errors, you need to manually \n",
    "            # delete the bad files or temporarily comment out this 'continue'\n",
    "            if os.path.exists(patch_filename):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # 1. Get Cropping Coordinates\n",
    "                try:\n",
    "                    bbox_list = literal_eval(row['bbox'])\n",
    "                except (ValueError, TypeError):\n",
    "                    bbox_list = row['bbox']\n",
    "                    \n",
    "                # -----------------------------------------------------\n",
    "                # --- APPLY NUMERIC STABILITY & PADDING ---\n",
    "                # -----------------------------------------------------\n",
    "                \n",
    "                # Apply stable rounding for the core 50x50 box:\n",
    "                # xmin/ymin (top-left) use floor\n",
    "                xmin_core = math.floor(float(bbox_list[0]))\n",
    "                ymin_core = math.floor(float(bbox_list[1]))\n",
    "                # xmax/ymax (bottom-right) use ceil\n",
    "                xmax_core = math.ceil(float(bbox_list[2]))\n",
    "                ymax_core = math.ceil(float(bbox_list[3]))\n",
    "\n",
    "                # Apply Padding to the core coordinates\n",
    "                xmin_padded = xmin_core - PADDING\n",
    "                ymin_padded = ymin_core - PADDING\n",
    "                xmax_padded = xmax_core + PADDING\n",
    "                ymax_padded = ymax_core + PADDING\n",
    "                \n",
    "                # 2. Crop from the image currently in memory\n",
    "                # PIL crop uses (left, top, right, bottom)\n",
    "                cropped_image = current_image.crop((xmin_padded, ymin_padded, xmax_padded, ymax_padded))\n",
    "                \n",
    "                # -----------------------------------------------------\n",
    "                # --- GUARANTEE: Final Resizing Step to Prevent DataLoader Failures ---\n",
    "                # -----------------------------------------------------\n",
    "                if cropped_image.size != (TARGET_PATCH_DIMENSION, TARGET_PATCH_DIMENSION):\n",
    "                     # Resize is crucial to force the expected size (e.g., 60x60) \n",
    "                     # even if the crop went outside the original image boundary.\n",
    "                     # Image.Resampling.BILINEAR is a good quality resampling filter.\n",
    "                     cropped_image = cropped_image.resize((TARGET_PATCH_DIMENSION, TARGET_PATCH_DIMENSION), Image.Resampling.BILINEAR) \n",
    "\n",
    "                # 3. Save the Patch\n",
    "                cropped_image.save(patch_filename)\n",
    "                \n",
    "            except Exception as e:\n",
    "                tqdm_images.write(f\"Error processing patch {row['patch_id']} from image {file_id}: {e}\")\n",
    "                \n",
    "    print(f\"\\n✅ Optimized pre-processing complete. Patches ({TARGET_PATCH_DIMENSION}x{TARGET_PATCH_DIMENSION}) saved to:\", target_patch_dir)\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a2506de-3b43-4fe2-92cf-33c5db1ea655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             bbox     labels  category_id  image_id  \\\n",
      "0          [4336, 346, 4386, 396]     [2, 2]            2         1   \n",
      "1            [756, 872, 806, 922]     [2, 2]            2         1   \n",
      "2          [270, 4044, 320, 4094]     [2, 2]            2         1   \n",
      "3  [6672.5, 706.5, 6722.5, 756.5]  [2, 1, 2]            2         1   \n",
      "4          [1872, 319, 1922, 369]     [2, 2]            2         2   \n",
      "\n",
      "                 Tumor       Scanner       Origin Species  \n",
      "0  human breast cancer  Hamamatsu XR  UMC Utrecht   Human  \n",
      "1  human breast cancer  Hamamatsu XR  UMC Utrecht   Human  \n",
      "2  human breast cancer  Hamamatsu XR  UMC Utrecht   Human  \n",
      "3  human breast cancer  Hamamatsu XR  UMC Utrecht   Human  \n",
      "4  human breast cancer  Hamamatsu XR  UMC Utrecht   Human  \n"
     ]
    }
   ],
   "source": [
    "from loaders import image_to_df\n",
    "\n",
    "df_merged = image_to_df()\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca9b1aa2-8986-4b48-b57b-78e291015a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimized pre-processing and saving of 60x60 image patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 26286 patches from 503 images: 100%|███████████████████████████████████████| 503/503 [17:18<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Optimized pre-processing complete. Patches (60x60) saved to: cropped_images_padded_60x60/\n"
     ]
    }
   ],
   "source": [
    "df_processed = preprocess_and_save_patches_optimized(df_merged)\n",
    "df_processed.to_csv('processed_annotations_with_patch_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea05190-b2a0-4045-b8f7-931ee61e597c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
